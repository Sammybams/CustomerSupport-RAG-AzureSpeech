{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Add OpenAI library\n",
    "import openai\n",
    "\n",
    "# Get Configuration Settings\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.28.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure OpenAI API using Azure OpenAI\n",
    "openai.api_key = os.getenv(\"API_KEY\")\n",
    "openai.api_base = os.getenv(\"ENDPOINT\")\n",
    "openai.api_type = \"azure\"  # Necessary for using the OpenAI library with Azure OpenAI\n",
    "openai.api_version = \"2024-02-01\"  # Latest / target version of the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI Settings\n",
    "model_deployment = \"text-embedding-ada-002\"\n",
    "# SDK calls this \"engine\", but naming it \"deployment_name\" for clarity\n",
    "\n",
    "model_name = \"text-embedding-ada-002\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/m3wgz92x6vj1gkr9lwh0893c0000gn/T/ipykernel_880/3172091303.py:1: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  openai_embeddings: OpenAIEmbeddings = OpenAIEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "openai_embeddings: OpenAIEmbeddings = OpenAIEmbeddings(\n",
    "    openai_api_version = os.getenv(\"OPENAI_API_VERSION\"), openai_api_key = os.getenv(\"API_KEY\"),\n",
    "    openai_api_base = os.getenv(\"ENDPOINT\"), openai_api_type = \"azure\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "vector_store_contoso = Chroma(\n",
    "    collection_name=\"Contoso-Outdoor-Docs\",\n",
    "    embedding_function=openai_embeddings,\n",
    "    persist_directory=\"../Contoso-Outdoor-Vector-DB\",  # Where to save data locally, remove if not neccesary\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index markdown files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "def load_and_process_markdowns(pdf_folder_path):\n",
    "        \"\"\"\n",
    "        This method is responsible for upserting PDF content.\n",
    "        It loads the PDF file, splits the content into chunks, and then upserts the chunks into VecDB.\n",
    "        \"\"\"\n",
    "        documents = []\n",
    "        for file in os.listdir(pdf_folder_path):\n",
    "            if file.endswith(\".md\"):\n",
    "                pdf_path = os.path.join(pdf_folder_path, file)\n",
    "                loader = UnstructuredMarkdownLoader(pdf_path)\n",
    "                documents.extend(loader.load())\n",
    "        \n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=150, separators=[\"\\n\", \" \", \"?\", \".\", \"!\"])\n",
    "        docs = text_splitter.split_documents(documents)\n",
    "        return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_folder_path =  \"../data/manual_info\"\n",
    "splits = load_and_process_markdowns(markdown_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': '../data/manual_info/product_info_2.md'}, page_content='Information about product item_number: 2\\n\\nAdventurer Pro Backpack, price $90,\\n\\nBrand\\n\\nHikeMate\\n\\nCategory\\n\\nBackpacks\\n\\nFeatures\\n\\n40L capacity for ample storage space\\n\\nErgonomic design for comfortable carrying\\n\\nDurable nylon material for long-lasting performance\\n\\nMultiple compartments and pockets for organized storage\\n\\nHydration system compatibility with a dedicated hydration bladder sleeve and tube port\\n\\nAdjustable and padded shoulder straps for a customized fit and enhanced comfort')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(splits))\n",
    "splits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upserting 0 documents\n",
      "Upserting 50 documents\n",
      "Upserting 100 documents\n",
      "Upserting 150 documents\n",
      "Upserting 200 documents\n",
      "Upserting 250 documents\n",
      "Upserting 300 documents\n",
      "Upserting 350 documents\n",
      "Upserting 400 documents\n",
      "Upserting 450 documents\n",
      "Upserting 500 documents\n",
      "Upserting 550 documents\n",
      "Upserting 600 documents\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from uuid import uuid4\n",
    "\n",
    "batch_size = 50  # Adjust this batch size based on your rate limit\n",
    "delay = 60  # Delay in seconds between batches\n",
    "\n",
    "for i in range(0, len(splits), batch_size):\n",
    "    batch = splits[i:i+batch_size]\n",
    "    uuids = [str(uuid4()) for _ in range(len(batch))]\n",
    "    print(f\"Upserting {i} documents\")\n",
    "    # try:\n",
    "    response = vector_store_contoso.add_documents(documents=batch, ids=uuids)\n",
    "    #     print(f\"Response: {response}\")\n",
    "    # except Exception as e:\n",
    "    #     print(e)\n",
    "    time.sleep(delay)  # Delay to prevent hitting rate limits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index json files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CustomerSupport-RAG-AzureSpeech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
